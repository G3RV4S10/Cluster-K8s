# Kubernetes Cluster â€“ Arquitetura de Control Plane e Worker Nodes

## DocumentaÃ§Ã£o "Hard Way"....


![Status](https://img.shields.io/badge/Status-Operational-success?style=flat-square) 
![Kubernetes](https://img.shields.io/badge/Kubernetes-v1.35.0-blue?style=flat-square) 
![OS](https://img.shields.io/badge/OS-Debian_13_(Trixie)-red?style=flat-square)

## ğŸ“Œ VisÃ£o Geral
Este repositÃ³rio documenta a criaÃ§Ã£o de um **cluster Kubernetes** composto por **1 Control Plane** e **3 Worker Nodes**, com foco em **boas prÃ¡ticas de arquitetura**, **decisÃµes tÃ©cnicas justificadas** e **padrÃµes prÃ³ximos de ambiente corporativo/SRE**.

O objetivo nÃ£o Ã© apenas "subir um cluster", mas **projetar uma infraestrutura consistente**, observÃ¡vel e preparada para crescimento controlado.

A implementaÃ§Ã£o segue a filosofia "Hard Way" (via `kubeadm`), enfrentando cenÃ¡rios reais de restriÃ§Ã£o de rede (Proxy Corporativo) e customizaÃ§Ãµes de kernel.

---

## ğŸ“š NavegaÃ§Ã£o da DocumentaÃ§Ã£o TÃ©cnica
O detalhamento passo-a-passo da implementaÃ§Ã£o encontra-se na pasta `/docs`:

1. [**PrÃ©-requisitos de Sistema**](docs/01-pre-requisitos-rede-os.md) - *Kernel 6.12, Swap, Proxy e Sysctl.*
2. [**Container Runtime**](docs/02-container-runtime.md) - *Containerd com Systemd Cgroup (CorreÃ§Ã£o CrÃ­tica).*
3. [**InstalaÃ§Ã£o de Pacotes**](docs/03-kubernetes-install.md) - *Kubeadm, Kubelet e Kubectl.*
4. [**Cluster Bootstrap**](docs/04-cluster-bootstrap.md) - *InicializaÃ§Ã£o do Control Plane.*
5. [**Rede e CNI (Calico)**](docs/05-rede-cni-calico.md) - *SoluÃ§Ã£o de problemas de Path CNI no Debian.*
6. [**Worker Nodes**](docs/06-adicionando-workers.md) - *Join e validaÃ§Ã£o.*
7. [**MetalLB - Load Balancer**](docs/07-loadbalancer-metallb.md) - *In progress.*

---

## ğŸ—ï¸ Arquitetura do Cluster

- **1Ã— Control Plane** (API Server, Scheduler, Controller Manager, etcd)
- **3Ã— Worker Nodes** (Workloads(pods), Kubelet, Containerd)
- **Rede:** Project Calico (Tigera Operator)
- **OS:** Debian Linux 13 (Trixie)

Todos os nÃ³s utilizam **Debian Linux** como sistema operacional base.

---

## ğŸ› ï¸ Desafios de Engenharia Superados

Durante a implementaÃ§Ã£o, decisÃµes especÃ­ficas foram tomadas para garantir estabilidade em ambiente virtualizado corporativo:

### 1. Alinhamento de Cgroups (Systemd)
O `containerd` padrÃ£o utiliza `cgroupfs`, enquanto o Kubernetes requer `systemd`. A discrepÃ¢ncia causa falha silenciosa no Kubelet.
* **SoluÃ§Ã£o:** ForÃ§ar `SystemdCgroup = true` no `config.toml` do containerd.

### 2. IntegraÃ§Ã£o de Rede (CNI Path)
O Debian 13 e o Calico possuem divergÃªncia no diretÃ³rio de binÃ¡rios CNI (`/usr/lib/cni` vs `/opt/cni/bin`), causando falha nos pods `calico-node`.
* **SoluÃ§Ã£o:** Download manual dos plugins CNI v1.3.0 e replicaÃ§Ã£o dos binÃ¡rios para ambos os diretÃ³rios de sistema.

### 3. Proxy Transparente
ConfiguraÃ§Ã£o de variÃ¡veis `no_proxy` granulares para garantir que o trÃ¡fego do Pod CIDR (`192.168.0.0/16`) e Service CIDR nÃ£o colida com o gateway corporativo.

---

## EstratÃ©gia de Particionamento & Storage
O particionamento utiliza **Btrfs** para evitar indisponibilidade e facilitar snapshots.

O particionamento foi pensado para:
- Evitar indisponibilidade por disco cheio
- Isolar crescimento de logs e containers
- Facilitar troubleshooting
- Manter simplicidade sem sacrificar boas prÃ¡ticas

### ğŸ” Control Plane â€“ Layout de Disco

| Ponto de Montagem | Tamanho | FS     | Justificativa |
|------------------|---------|--------|---------------|
| /boot            | 528 MB  | ext4   | Boot estÃ¡vel e compatÃ­vel |
| /                | 25 GB   | btrfs  | Sistema base e binÃ¡rios |
| /var             | 43.2 GB | btrfs  | Logs, containers, kubelet e etcd |

### DecisÃµes de Filesystem
* **Btrfs:** Escolhido por suporte a subvolumes e snapshots.
- Suporte a subvolumes
- Snapshots seletivos
- CompressÃ£o transparente
- Facilidade de rollback
* **Sem `/home` separado, Por que **nÃ£o** criar `/home`?:** 
- NÃ³s Kubernetes nÃ£o sÃ£o estaÃ§Ãµes de trabalho
- NÃ£o hÃ¡ usuÃ¡rios interativos
- Nenhum dado persistente de aplicaÃ§Ã£o deve residir localmente

### /usr separado
- Sistemas modernos (systemd) nÃ£o se beneficiam
- Pode causar problemas no boot
- Mantido junto com `/`
---

## DecisÃµes TÃ©cnicas Importantes
### Swap - Totalmente desabilitado (requisitos do kubelet)
- Swap **nÃ£o Ã© utilizada**
- Kubernetes exige swap desativada por padrÃ£o
- Evita comportamento imprevisÃ­vel de memÃ³ria

---

### Subvolumes recomendados em `/var`

```
/var/log
/var/lib/containerd
/var/lib/kubelet
/var/lib/etcd   # apenas no control plane
```

### AtenÃ§Ã£o: etcd e Copy-on-Write

O etcd Ã© extremamente sensÃ­vel a latÃªncia de disco.

â¡ **Copy-on-Write Ã© desativado para o diretÃ³rio do etcd**:

```bash
chattr +C /var/lib/etcd
```

Essa prÃ¡tica reduz risco de degradaÃ§Ã£o de performance e corrupÃ§Ã£o de dados.

---

## OpÃ§Ãµes de Montagem (Mount Options)

Recomendadas para `/` e `/var`:

```
noatime,compress=zstd
```

BenefÃ­cios:
- Menor I/O
- Logs mais leves
- Melhor desempenho geral

---

## Objetivo do Projeto

Este projeto serve como:
- LaboratÃ³rio avanÃ§ado de Kubernetes
- Base para estudos de DevOps / SRE
- PortfÃ³lio tÃ©cnico documentado
- ReferÃªncia de boas prÃ¡ticas de infraestrutura

---

## PrÃ³ximos Passos

- [x] InicializaÃ§Ã£o do cluster com kubeadm
- [x] Networking (CNI) - Calico (Configurado e Operacional)
- [ ] Networking (CNI) - Canal - Explorar futuramente - JunÃ§Ã£o do Flannel e Calico
- [x] DocumentaÃ§Ã£o de troubleshooting (CNI e Runtime)
- [ ] Hardening bÃ¡sico de seguranÃ§a
- [ ] Monitoramento (Prometheus + Grafana)
- [ ] Backup do etcd
- [ ] DocumentaÃ§Ã£o de troubleshooting


---

#### ObservaÃ§Ã£o Final

Todas as decisÃµes aqui documentadas sÃ£o **intencionais**, **justificadas** e alinhadas com cenÃ¡rios reais de operaÃ§Ã£o.

> Infraestrutura nÃ£o Ã© sobre instalar â€” Ã© sobre **sustentar**.

---
ğŸ“ LicenÃ§a
MIT License - Copyright (c) 2026 Gervasio
